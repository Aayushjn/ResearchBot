from hashlib import shake_256

from dtypes import Paper

PAPER_DATA = {
    "image classification": {
        "f55c3d53eaacc75f497a55ab349276b18ea98cc1": {
            "title": "Fused Node-Level Residual Structure Edge Graph Neural Network for Few-Shot Image Classification",
            "abstract": "In spite of recent rapid developments across various computer vision domains, numerous cutting-edge deep learning algorithms often demand a substantial volume of data to operate effectively. Within this research, a novel few-shot learning approach is presented with the objective of enhancing the accuracy of few-shot image classification. This task entails the classification of unlabeled query samples based on a limited set of labeled support examples. Specifically, the integration of the edge-conditioned graph neural network (EGNN) framework with hierarchical node residual connections is proposed. The primary aim is to enhance the performance of graph neural networks when applied to few-shot classification, a rather unconventional application of hierarchical node residual structures in few-shot image classification tasks. It is noteworthy that this work represents an innovative attempt to combine these two techniques. Extensive experimental findings on publicly available datasets demonstrate that the methodology surpasses the original EGNN algorithm, achieving a maximum improvement of 2.7%. Particularly significant is the performance gain observed on our custom-built dataset, CBAC (Car Brand Appearance Classification), which consistently outperforms the original method, reaching an impressive peak improvement of 11.14%.",
            "pdf_url": "https://www.mdpi.com/2076-3417/13/19/10996/pdf?version=1696651596",
            "summary": "A novel few-shot learning approach is presented with the objective of enhancing the accuracy of few- shot image classification, and the integration of the edge-conditioned graph neural network (EGNN) framework with hierarchical node residual connections is proposed.",
        },
        "969616fc1b82807ee7fb0f7f03f60972e8e6f6c3": {
            "title": "RS Invariant Image Classification and Retrieval with Pretrained Deep Learning Models",
            "abstract": "—CBIR deals with seeking of related images from large dataset, like Internet is a demanding task. Since last two decades scientists are working in this area in various angles. Deep learning provided state-of-the art result for image categorization and recovery. But pre-trained deep learning models are not strong enough to rotation and scale variations. A technique is proposed in this work to improve the precision and recall of image retrieval. This method concentrates on the extraction of high-level features with rotation and scaling invariant from ResNet18 CNN (Convolutional Neural Network) model. These features used for segregation of images using VGG19 deep learning model. Finally, after classification if the class of given query image is correct, we will get the 100% results for both precision and recall as the ideal requirement of image retrieval technique. Our experimental results shows that not only our proposed technique outstrip current techniques for rotated and scaled query images but also it has preferable results for retrieval time requirements. The performance investigation exhibit that the presented method upgrades the average precision value from 76.50% for combined features DCD (Dominant Color Descriptor), wavelet and curvelet to 99.1% and average recall value from 14.21% to 19.82% for rotated and scaled images utilizing Corel dataset. Also, the average retrieval time required is 1.39 sec, which is lower than existing modern techniques.",
            "pdf_url": "http://thesai.org/Downloads/Volume13No6/Paper_51-RS_Invariant_Image_Classification_and_Retrieval.pdf",
            "summary": "The proposed technique concentrates on the extraction of high-level features with rotation and scaling invariant from ResNet18 CNN (Convolutional Neural Network) model to improve the precision and recall of image retrieval.",
        },
        "c11c95de36e9337db59e3f21d335f24b60097fff": {
            "title": "Classification on Unsupervised Deep Hashing With Pseudo Labels Using Support Vector Machine for Scalable Image Retrieval",
            "abstract": "The content-based image retrieval (CBIR) method operates on the low-level visual features of the user input query object, which makes it difficult for users to formulate the query and also does not provide adequate retrieval results. In the past, image annotation was suggested as the best possible framework for CBIR, which works on automatically signing keywords to images that support image retrieval. The recent successes of deep learning techniques, especially Convolutional Neural Networks (CNN), in solving computer vision applications have inspired me to work on this paper to solve the problem of CBIR using a dataset of annotated images",
            "pdf_url": "https://wjcm.uowasit.edu.iq/index.php/wjcm/article/download/147/95",
            "summary": "The recent successes of deep learning techniques, especially Convolutional Neural Networks (CNN), in solving computer vision applications have inspired me to work on this paper to solve the problem of CBIR using a dataset of annotated images.",
        },
        "2c95fb83c47fa145ef87188d6e61731717b4fa74": {
            "title": "Automatic Medical X-ray Image Classification using Annotation",
            "abstract": "The demand for automatically classification of medical X-ray images is rising faster than ever. In this paper, an approach is presented to gain high accuracy rate for those classes of medical database with high ratio of intraclass variability and interclass similarities. The classification framework was constructed via annotation using the following three techniques: annotation by binary classification, annotation by probabilistic latent semantic analysis, and annotation using top similar images. Next, final annotation was constructed by applying ranking similarity on annotated keywords made by each technique. The final annotation keywords were then divided into three levels according to the body region, specific bone structure in body region as well as imaging direction. Different weights were given to each level of the keywords; they are then used to calculate the weightage for each category of medical images based on their ground truth annotation. The weightage computed from the generated annotation of query image was compared with the weightage of each category of medical images, and then the query image would be assigned to the category with closest weightage to the query image. The average accuracy rate reported is 87.5 %.",
            "pdf_url": "https://europepmc.org/articles/pmc3903972?pdf=render",
            "summary": "An approach is presented to gain high accuracy rate for those classes of medical database with high ratio of intraclass variability and interclass similarities with average accuracy rate of 87.5 %.",
        },
        "83b78d918b0f1842aba38c6e9f321645a641cf43": {
            "title": "Clothing Genre Recognition System Using Image Processing Techniques- A Survey",
            "abstract": ". Nowadays, Clothing business is one of the mostimportantcomponentsinthee-commerceindustry. So, there is plenty of online clothing sites are available where people can search and retrieve the most clothing items for their user query image. Clothing genre recognition is a very active topic in computer vision and multimedia research. In the textile industry, image processing techniques provide sensitive attention in the fieldoftheimage-basedclothingrecognitionsystem.The sequence of cloth images can be given as input to the recognition system. This clothing genre recognition system helps to detect the patterns and features of cloths which helps to classify them using effective feature extraction and classification algorithms. Feature extractiontechniquescanbeusedtoobtainfeaturesfrom thecloths.Classificationalgorithmsfromsoftcomputing help to automatically classify clothes genres depending on style elements and their salient visual features. Deep learning and Support Vector Machine (SVM) classifier achieved better performance in classifying both upper wear and lower wear genres. The main motivations of this paper focus on automatically classifying both upper wearandlowerweargenrefromafull-bodyinputimage. Evaluation metrics like precision, recall, F-score were used to measure the classification accuracy.This paper addresses on issues, challenges, applications, frameworks, tools, and techniques for recognition of clothing genres is carriedout.",
            "pdf_url": "http://eudl.eu/pdf/10.4108/eai.16-5-2020.2303969",
            "summary": "The main motivations of this paper focus on automatically classifying both upper wear and lower weargenrefromafull-bodyinput image, and evaluation metrics like precision, recall, F-score were used to measure the classification accuracy.",
        },
        "e31388ec299f9a9e68e1d6ced66b279f7e3f4f4f": {
            "title": "A Systematic Review on Knowledge Graphs Classiﬁcation and Their Various Usages",
            "abstract": "A Knowledge Graph is a directive graph where the nodes state the entities and the edges describe the relationships between the entities of data. It is also referred to as a Semantic Network. The massive amount of data generated every day can be transformed into knowledge via knowledge graphs for the effective use of these data. Knowing the classification of Knowledge Graphs is required to adapt to different requirements of Knowledge Graphs. Knowledge Graphs are primarily classified concerning their building techniques and their usages. In building techniques, it is considered how the Knowledge Graph is built. For example, the graph can be constructed as a triplet, quadruplet, etc., or created from structured data, e.g., database, or unstructured data, e.g., text, image, etc. On the other hand, Knowledge Graphs can be used for various purposes. For example, Knowledge Graphs can be used for Information Retrieval, Semantic Query, etc., or different types of data visualization. Nowadays, Knowledge Graph is one of the trending topics in the modern technology-dependent world. However, clear and specific discussions on the classifications of Knowledge Graphs and their various usages are less available. In this paper, we will describe the classification of knowledge graphs and their various usages in detail so that the readers can get a clear concept of this topic.",
            "pdf_url": "https://ojs.wiserpub.com/index.php/AIE/article/download/3605/1765",
            "summary": "The classification of knowledge graphs and their various usages in detail is described in detail so that the readers can get a clear concept of this topic.",
        },
        "f8306b6b07ecffb80b7dce9620b3c87aca6a3cd3": {
            "title": "High-Dimensional Similarity Query Processing for Data Science",
            "abstract": "Similarity query (a.k.a. nearest neighbor query) processing has been an active research topic for several decades. It is an essential procedure in a wide range of applications (e.g., classification & regression, deduplication, image retrieval, and recommender systems). Recently, representation learning and auto-encoding methods as well as pre-trained models have gained popularity. They basically deal with dense high-dimensional data, and this trend brings new opportunities and challenges to similarity query processing. Meanwhile, new techniques have emerged to tackle this long-standing problem theoretically and empirically. This tutorial aims to provide a comprehensive review of high-dimensional similarity query processing for data science. It introduces solutions from a variety of research communities, including data mining (DM), database (DB), machine learning (ML), computer vision (CV), natural language processing (NLP), and theoretical computer science (TCS), thereby highlighting the interplay between modern computer science and artificial intelligence technologies. We first discuss the importance of high-dimensional similarity query processing in data science applications, and then review query processing algorithms such as cover tree, locality sensitive hashing, product quantization, proximity graphs, as well as recent advancements such as learned indexes. We analyze their strengths and weaknesses and discuss the selection of algorithms in various application scenarios. Moreover, we consider the selectivity estimation of high-dimensional similarity queries, and show how researchers are bringing in state-of-the-art ML techniques to address this problem. We expect that this tutorial will provide an impetus towards new technologies for data science.",
            "pdf_url": "https://repository.hkust.edu.hk/ir/bitstream/1783.1-115884/1/115884-1.pdf",
            "summary": "This tutorial aims to provide a comprehensive review of high-dimensional similarity query processing for data science, and introduces solutions from a variety of research communities, including data mining (DM), database (DB), machine learning (ML), computer vision, natural language processing (NLP), and theoretical computer science (TCS), thereby highlighting the interplay between modern computer science and artificial intelligence technologies.",
        },
        "041d1f470cc2e150bfefae3ec1aeb206f02fdc9b": {
            "title": "Few-Shot Classification with Dual-Model Deep Feature Extraction and Similarity Measurement",
            "abstract": "From traditional machine learning to the latest deep learning classifiers, most models require a large amount of labeled data to perform optimal training and obtain the best performance. Yet, when limited training samples are available or when accompanied by noisy labels, severe degradation in accuracy can arise. The proposed work mainly focusses on these practical issues. Herein, standard datasets, i.e., Mini-ImageNet, CIFAR-FS, and CUB 200, are considered, which also have similar issues. The main goal is to utilize a few labeled data in the training stage, extracting image features and then performing feature similarity analysis across all samples. The highlighted aspects of the proposed method are as follows. (1) The main self-supervised learning strategies and augmentation techniques are exploited to obtain the best pretrained model. (2) An improved dual-model mechanism is proposed to train the support and query datasets with multiple training configurations. As examined in the experiments, the dual-model approach obtains superior performance of few-shot classification compared with all of the state-of-the-art methods.",
            "pdf_url": "https://www.mdpi.com/2079-9292/11/21/3502/pdf?version=1666956376",
            "summary": "The main goal is to utilize a few labeled data in the training stage, extracting image features and then performing feature similarity analysis across all samples, which obtains superior performance of few-shot classification compared with all of the state-of-the-art methods.",
        },
        "7e2689f1c14509cef2455171adb13e2412aebd3e": {
            "title": "Analysis of Content Based Image Retrieval using Deep Feature Extraction and Similarity Matching",
            "abstract": "—Image retrieval using a textual query becomes a major challenge mainly due to human perception subjectivity and the impreciseness of image annotations. These drawbacks can be overcome by focusing on the content of images rather than on the textual descriptions of images. Traditional feature extraction techniques demand for expert knowledge to select the limited feature types and are also sensitive to changing imaging conditions. Deep feature extraction using Convolutional Neural Network (CNN) are a solution to these drawbacks as they can learn the feature representations automatically. This work carries out a detailed performance comparison of various pre-trained models of CNN in feature extraction. Features are extracted from men footwear and women clothing datasets using the VGG16, VGG19, InceptionV3, Xception and ResNet50 models. Further, these extracted features are used for classification using SVM, Random Forest and K-Nearest Neighbors classifiers. Results of feature extraction and image retrieval show that VGG19, Inception and Xception features perform well with feature extraction, achieving a good image classification accuracy of 97.5%. These results are further justified by performing a comparison of image retrieval efficiency, with the extracted features and similarity metrics. This work also compares the accuracy obtained by features extracted by the selected pre-trained CNN models with the results obtained using conventional classification techniques on CIFAR 10 dataset. The features extracted using CNN can be used in image-based systems like recommender systems, where images have to be analyzed to generate item profiles.",
            "pdf_url": "http://thesai.org/Downloads/Volume13No12/Paper_77-Analysis_of_Content_Based_Image_Retrieval.pdf",
            "summary": "Results of feature extraction and image retrieval show that VGG19, Inception and Xception features perform well with feature extraction, achieving a good image classification accuracy of 97.5%.",
        },
        "35ed6dda6bd0be3083034bb43481d6273c911205": {
            "title": "Spatial Prior Fuzziness Pool-Based Interactive Classification of Hyperspectral Images",
            "abstract": "Acquisition of labeled data for supervised Hyperspectral Image (HSI) classification is expensive in terms of both time and costs. Moreover, manual selection and labeling are often subjective and tend to induce redundancy into the classifier. Active learning (AL) can be a suitable approach for HSI classification as it integrates data acquisition to the classifier design by ranking the unlabeled data to provide advice for the next query that has the highest training utility. However, multiclass AL techniques tend to include redundant samples into the classifier to some extent. This paper addresses such a problem by introducing an AL pipeline which preserves the most representative and spatially heterogeneous samples. The adopted strategy for sample selection utilizes fuzziness to assess the mapping between actual output and the approximated a-posteriori probabilities, computed by a marginal probability distribution based on discriminative random fields. The samples selected in each iteration are then provided to the spectral angle mapper-based objective function to reduce the inter-class redundancy. Experiments on five HSI benchmark datasets confirmed that the proposed Fuzziness and Spectral Angle Mapper (FSAM)-AL pipeline presents competitive results compared to the state-of-the-art sample selection techniques, leading to lower computational requirements.",
            "pdf_url": "https://www.mdpi.com/2072-4292/11/9/1136/pdf?version=1557829096",
            "summary": "Experiments on five HSI benchmark datasets confirmed that the proposed Fuzziness and Spectral Angle Mapper-AL pipeline presents competitive results compared to the state-of-the-art sample selection techniques, leading to lower computational requirements.",
        },
        "0cafd3d32af0628487d8a2f0e72ade2a9c9ef288": {
            "title": "Enhanced Semantic Image Retrieval using Feature Extraction and KNN Techniques",
            "abstract": "In addition of that, the technique required some additional techniques to correct the retrieval process such as user feedback, these methods consumes additional time of search. Thus a new technique with hybrid concept is proposed for improving the content based image search. The proposed technique includes the technique to train the system using the image features and text for annotation of image. For identifying the images more accurately the text and image features are used. Finally to retrieve the data (image) using user query (image or text) a KNN algorithm is implemented with it. The implementation of the proposed model is performed using visual studio technology and their performance in terms of time and space complexity is estimated. In addition of that the performance in terms of accuracy and error rate is also provided for demonstrating the relevancy of image search. General Terms Your general terms must be any term which can be used for general classification of the submitted material such as Pattern Recognition, Security, Algorithms et. al.",
            "pdf_url": "http://www.ijcaonline.org/research/volume136/number13/rastogi-2016-ijca-908582.pdf",
            "summary": "A new technique with hybrid concept is proposed for improving the content based image search by including the technique to train the system using the image features and text for annotation of image.",
        },
        "0b5594bdedb33b4ace17c6f7047c4dde3ac3082c": {
            "title": "Diminishing Uncertainty Within the Training Pool: Active Learning for Medical Image Segmentation",
            "abstract": "Active learning is a unique abstraction of machine learning techniques where the model/algorithm could guide users for annotation of a set of data points that would be beneficial to the model, unlike passive machine learning. The primary advantage being that active learning frameworks select data points that can accelerate the learning process of a model and can reduce the amount of data needed to achieve full accuracy as compared to a model trained on a randomly acquired data set. Multiple frameworks for active learning combined with deep learning have been proposed, and the majority of them are dedicated to classification tasks. Herein, we explore active learning for the task of segmentation of medical imaging data sets. We investigate our proposed framework using two datasets: 1.) MRI scans of the hippocampus, 2.) CT scans of pancreas and tumors. This work presents a query-by-committee approach for active learning where a joint optimizer is used for the committee. At the same time, we propose three new strategies for active learning: 1.) increasing frequency of uncertain data to bias the training data set; 2.) Using mutual information among the input images as a regularizer for acquisition to ensure diversity in the training dataset; 3.) adaptation of Dice log-likelihood for Stein variational gradient descent (SVGD). The results indicate an improvement in terms of data reduction by achieving full accuracy while only using 22.69% and 48.85% of the available data for each dataset, respectively.",
            "pdf_url": "https://arxiv.org/pdf/2101.02323",
            "summary": "This work presents a query-by-committee approach for active learning where a joint optimizer is used for the committee to explore active learning for the task of segmentation of medical imaging data sets.",
        },
        "61172a3b49b89d04015f1abde801737a7a14ca65": {
            "title": "A novel priority based document image encryption with mixed chaotic systems using machine learning approach",
            "abstract": "Document images containing different types of information are required to be\n encrypted with different levels of security. In this paper, the image\n classification is carried out based on the feature extraction, for color\n images. The K-Nearest Neighbor (K-NN) method of image classification\n technique is used for classifying the query Document with trained set of\n features obtained from the Document database. Optical Character Recognition\n (OCR) technique is used to check for the presence as well as location of\n text/numerals in the Documents and to identify the Document type. Priority\n level is assigned in accordance with the Document type. Document images with\n different priorities are encrypted with different multi-dimensional chaotic\n maps. The Documents with different priority levels are diffused with\n different techniques. Document with highest priority are encrypted with\n highest level of security but Documents with lower priority levels are\n encrypted with lesser security levels. The proposed work was experimented\n for different document types with more number of image features for a large\n trained database. The results reveals a high speed of encryption for a set\n of document pages with priorities is more effective in comparison with a\n uniform method of encryption for all document types. The National Institute\n of Standards and Technology (NIST) statistical tests are also conducted to\n check for the randomness of the sequence and achieved good randomness. The\n proposed work also ensures security against the various statistical and\n differential attacks.",
            "pdf_url": "http://www.doiserbia.nb.rs/ft.aspx?id=0353-36701901147R",
            "summary": "The K-Nearest Neighbor (K-NN) method of image classification  technique is used for classifying the query Document with trained set of features obtained from the Document database, based on the feature extraction, for color images.",
        },
        "3b639427d8e1a9d7b0672a8f6af4075e35e27f2d": {
            "title": "Metric Indexing for the Earth Mover's Distance",
            "abstract": "The Earth Mover's Distance (EMD) has become a popular choice for applications in similarity search, particularly in applications such as few-shot image classification where it is observed to match human perceptions of image differences better than other distance measures such as the Euclidean distance. Currently, in domains such as few-shot image classification, it is common to use exhaustive search during query time which is inefficient in applications using distances with high computational complexity such as the EMD. Since the space in these applications is not guaranteed to be a vector space, existing techniques such as product quantization cannot be applied. In this paper, we study the application of metric space indexing structures towards the reduction of the number of EMD computations needed during query time. We conduct experiments on several image datasets in order to identify the advantages and disadvantages of different metric space data structures. These experiments have not been performed in the context of the EMD before and demonstrate that the VP-tree is more robust to increases in dataset complexity in this domain than comparable metric indexing data structures. Furthermore, we combine these data structures with deep feature extraction to develop a method for efficient deep image retrieval in metric spaces. Taking inspiration from distance stretching methods in the previous literature, we develop a novel approximate nearest neighbor algorithm for k-NN search that can greatly reduce the number of distance computations needed for retrieval without significantly changing k-NN accuracy.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3615890.3628531",
            "summary": "A novel approximate nearest neighbor algorithm for k-NN search that can greatly reduce the number of distance computations needed for retrieval without significantly changing k-nn accuracy is developed.",
        },
        "5dac2f75c67c7be80ea666a4b6c86953c9990b63": {
            "title": "Improving Cassification Engine in Content based Image Retrieval by Multi-point Queries via Pareto Approach",
            "abstract": "Machine learning methods have demonstrated promising performance for Content Based Image Retrieval (CBIR) using Relevance Feedback (RF). However, a very limited number of feedback images can significantly degrade the performance of these techniques. In this work, each image is represented by a vector of multiple distance measures corresponding to multiple features. Each feature is considered a sub-query for RF process. In RF process, we propose to use Pareto method to get Pareto points (also called trade-off points) according to different depths. These points are used as relevant queries for the next RF round. Experimental results show that our proposed approach is very effective to improve the performance of the classification engine.",
            "pdf_url": "http://www.rgnpublications.com/journals/index.php/jims/article/download/456/686",
            "summary": "Experimental results show that the proposed approach to use Pareto method to get Pare to points is very effective to improve the performance of the classification engine.",
        },
    },
    "llm in education": {
        "7c04ab297b59d4fe29285f339350882a3120b27f": {
            "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
            "abstract": "Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.",
            "pdf_url": "https://export.arxiv.org/pdf/2401.11314v2.pdf",
            "summary": "CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions, is developed, revealing four design considerations for future educational AI assistants.",
        },
        "69dc9343d4e443cf7cfbd344a9a2cc9f8553e254": {
            "title": "Debugging with an AI Tutor: Investigating Novice Help-seeking Behaviors and Perceived Learning",
            "abstract": "Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3632620.3671092",
            "summary": "",
        },
        "b640fe51d6d30af38a0f4e56c6994b27a0de1064": {
            "title": "Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms",
            "abstract": "We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300534",
            "summary": "The technology has the potential to support teachers' role of being a coach in technology-mediated learning environments and has a significant impact on the teacher's classroom practices and student engagement.",
        },
        "ffeb5d6295763c06f750dbed2efb08524ed49bbc": {
            "title": "Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning",
            "abstract": "Like anyone, teachers need feedback to improve. Due to the high cost of human classroom observation, teachers receive infrequent feedback which is often more focused on evaluating performance than on improving practice. To address this critical barrier to teacher learning, we aim to provide teachers with detailed and actionable automated feedback. Towards this end, we developed an approach that enables teachers to easily record high-quality audio from their classes. Using this approach, teachers recorded 142 classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition and machine learning to develop teacher-generalizable computer-scored estimates of key dimensions of teacher discourse. We found that automated models were moderately accurate when compared to human coders and that speech recognition errors did not influence performance. We conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback. Our next step is to incorporate the automatic models into an interactive visualization tool that will provide teachers with objective feedback on the quality of their discourse.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376418",
            "summary": "An approach that enables teachers to easily record high-quality audio from their classes and develops teacher-generalizable computer-scored estimates of key dimensions of teacher discourse, which conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback.",
        },
        "b103e87c7727134927d3ffb06934a95c10c02fc0": {
            "title": "GPT-3: Its Nature, Scope, Limits, and Consequences",
            "abstract": "In this commentary, we discuss the nature of reversible and irreversible questions, that is, questions that may enable one to identify the nature of the source of their answers. We then introduce GPT-3, a third-generation, autoregressive language model that uses deep learning to produce human-like texts, and use the previous distinction to analyse it. We expand the analysis to present three tests based on mathematical, semantic (that is, the Turing Test), and ethical questions and show that GPT-3 is not designed to pass any of them. This is a reminder that GPT-3 does not do what it is not supposed to do, and that any interpretation of GPT-3 as the beginning of the emergence of a general form of artificial intelligence is merely uninformed science fiction. We conclude by outlining some of the significant consequences of the industrialisation of automatic and cheap production of good, semantic artefacts.",
            "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11023-020-09548-1.pdf",
            "summary": "The nature of reversible and irreversible questions is discussed, that is, questions that may enable one to identify the nature of the source of their answers, and GPT-3, a third-generation, autoregressive language model that uses deep learning to produce human-like texts, is introduced.",
        },
        "1234": {
            "title": "The role and challenges of education for responsible AI",
            "abstract": "Artificial intelligence (AI) is impacting education in many different ways. From virtual assistants for personalized education, to student or teacher tracking systems, the potential benefits of AI for education often come with a discussion of its impact on privacy and well-being. At the same time, the social transformation brought about by AI requires reform of traditional education systems. This article discusses what a responsible, trustworthy vision for AI is and how this relates to and affects education. ",
            "pdf_url": "https://journals.uclpress.co.uk/lre/article/129/galley/17508/download/",
            "summary": "",
        },
        "979eb5c97c49d7979447ed684500895a24d75ac4": {
            "title": "The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming",
            "abstract": "Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing, in particular, has been transformed by machine learning models such as OpenAI’s GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex, a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input, Codex generates solution code as output. It can also explain (in English) input code, translate code between programming languages, and more. In this work, we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known “Rainfall Problem” along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions, observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally, we discuss the implications that such technology will have for computing education as it continues to evolve, including both challenges and opportunities.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3511861.3511863",
            "summary": "This work explores how Codex performs on typical introductory programming problems, and reports its performance on real questions taken from introductory programming exams and compares it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students.",
        },
        "78c0b63d1442fe79bb3a9ce56fa5c293aacf8ea2": {
            "title": "AI Education from the Educator’s Perspective: Best Practices for an Inclusive AI Curriculum for Middle School",
            "abstract": "Artificial Intelligence (AI) and its applications have a strong impact on people’s lives worldwide. Therefore, an increasing number of professionals and academics are focusing on the development of AI education programs for K-12. Part of these programs is developed for formal educational settings, such as school classrooms, which are complex systems with several variables interwoven. The current study concentrates on the teachers’ perspective on the implementation of an AI education curriculum for middle schools located in disadvantaged areas of Europe. Given these premises, a particular focus is devoted to how AI education can foster inclusion and be more accessible. Feedback was gathered through 582 logbooks provided by educators, and an international focus group conducted at the end of the curriculum implementation. This information helped to understand educators’ points of view on the AI curriculum, investigating how these topics can stimulate reflections around inclusion and diversity.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3544549.3585747",
            "summary": "This study concentrates on the teachers’ perspective on the implementation of an AI education curriculum for middle schools located in disadvantaged areas of Europe, investigating how these topics can stimulate reflections around inclusion and diversity.",
        },
        "c886d0e3bffa478bf5e01f2b9f4231d1d5e3fbd0": {
            "title": "How ChatGPT Will Change Software Engineering Education",
            "abstract": "This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3587102.3588815",
            "summary": "Why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning is pointed out.",
        },
        "5678": {
            "title": "My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises",
            "abstract": "The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3576123.3576134",
            "summary": "",
        },
        "dca3bc28a7d404b28780a813ea7072eda809e6c0": {
            "title": "Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation",
            "abstract": "The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.",
            "pdf_url": "https://export.arxiv.org/pdf/2212.01020v1.pdf",
            "summary": "It is argued that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges.",
        },
        "c75bc07358d6d8e4a6f278fb0a81aed741bf3a90": {
            "title": "Experiences with TA-Bot in CS1",
            "abstract": "Automated Assessment Tools (AATs) have been used in undergraduate CS education for decades. TA-Bot, a modular AAT, has existed in some form for 25 years serving thousands of students across multiple universities. Class sizes throughout the last decade have continued to grow, while the number of instructors remains stagnant. AATs help instructors mitigate issues without additional resources, while simultaneously providing students with helpful feedback. The research team implemented novel features into the new, web-based TA-Bot such as dynamic rate limiting between submissions, custom code style feedback, and a gamified points system. The experiment discussed in this paper used TA-Bot over the course of three semesters involving 145 students in CS1. During the first semester, student and instructor feedback was collected on how to improve the tool. The second semester was used to rate limit submissions using a new dynamic rate limiting system. Finally, the third semester of TA-Bot was used as a control group with simple submission input/output checking. Instructors found that TA-Bot helped mitigate issues with continual increases in class sizes. When using TA-Bot with a dynamic rate limit, students were more inclined to start their assignment earlier. In addition to this, TA-Bot provides students with the ability to compare their solution against test cases, while simultaneously providing code-style advice using curated novice-friendly examples.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3576882.3617930",
            "summary": "The research team implemented novel features into the new, web-based TA-Bot such as dynamic rate limiting between submissions, custom code style feedback, and a gamified points system to help instructors mitigate issues with continual increases in class sizes.",
        },
        "790284be3e6ae7286a0e0ab619e298f90f3a0eff": {
            "title": "Generative Artificial Intelligence and the Education Sector",
            "abstract": "Large language models (LLMs), such as ChatGPT and now GPT4, are considered a significant breakthrough in conversational artificial intelligence. Academic institutions have varying responses to LLMs in education, some banning LLMs and others encouraging them.",
            "pdf_url": "https://ieeexplore.ieee.org/ielx7/2/10132019/10132034.pdf?tag=1",
            "summary": "",
        },
        "0123": {
            "title": "GPT-3 vs Object Oriented Programming Assignments: An Experience Report",
            "abstract": "Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages. In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3587102.3588814",
            "summary": "",
        },
        "73746f32d61405c5e3c95a7165b03a9f92298f53": {
            "title": "Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments",
            "abstract": "Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course. We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3587102.3588852",
            "summary": "There was a high variability in the accuracy of the model's feedback for student written code, suggesting that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.",
        },
        "6d3f29545fa059f7d24e27aaa9351750636d12ce": {
            "title": "On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?",
            "abstract": "In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.",
            "pdf_url": "https://export.arxiv.org/pdf/2303.11146v1.pdf",
            "summary": "How computer science higher education should adapt to tools like ChatGPT is discussed, with a primary focus on computer security-oriented specialization.",
        },
        "5be9a64df5f8d7e5a33fcc2c7bdfcde1fbbd085a": {
            "title": "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions",
            "abstract": "The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.",
            "pdf_url": "https://pdfs.semanticscholar.org/737b/bcf513dfb66512c58bfe982f25f1485e0f7b.pdf",
            "summary": "This paper argues that it is paramount to understand both the potential and the pitfalls of LLMs in medical education, and proposes that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more.",
        },
        "6432154165": {
            "title": "Prompts First, Finally",
            "abstract": "Generative AI (GenAI) and large language models in particular, are disrupting Computer Science Education. They are proving increasingly capable at more and more challenges. Some educators argue that they pose a serious threat to computing education, and that we should ban their use in the classroom. While there are serious GenAI issues that remain unsolved, it may be useful in the present moment to step back and examine the overall trajectory of Computer Science writ large. Since the very beginning, our discipline has sought to increase the level of abstraction in each new representation. We have progressed from hardware dip switches, through special purpose languages and visual representations like flow charts, all the way now to ``natural language.'' With the advent of GenAI, students can finally change the abstraction level of a problem to the ``language'' they've been ``problem solving'' with all their lives. In this paper, we argue that our programming abstractions were always headed here -- to natural language. Now is the time to adopt a ``Prompts First'' approach to Computer Science Education. ",
            "pdf_url": "https://arxiv.org/pdf/2407.09231",
            "summary": "",
        },
        "5634528654312": {
            "title": "Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing",
            "abstract": "Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3657604.3662039",
            "summary": "",
        },
        "5461355768345": {
            "title": "Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts",
            "abstract": "This paper explores how instructors can leverage generative AI to create personalized learning experiences for students that transform teaching and learning. We present a range of AI-based exercises that enable novel forms of practice and application including simulations, mentoring, coaching, and co-creation. For each type of exercise, we provide prompts that instructors can customize, along with guidance on classroom implementation, assessment, and risks to consider. We also provide blueprints, prompts that help instructors create their own original prompts. Instructors can leverage their content and pedagogical expertise to design these experiences, putting them in the role of builders and innovators. We argue that this instructor-driven approach has the potential to democratize the development of educational technology by enabling individual instructors to create AI exercises and tools tailored to their students' needs. While the exercises in this paper are a starting point, not a definitive solutions, they demonstrate AI's potential to expand what is possible in teaching and learning.",
            "pdf_url": "https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4802463_code1503159.pdf?abstractid=4802463&mirid=1",
            "summary": "",
        },
        "645123578645321": {
            "title": "Analyzing Students’ Preferences for LLM-Generated Analogies",
            "abstract": "Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.",
            "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3649405.3659504",
            "summary": "",
        },
        "2f3eaca83964085eab1c8d014e2993185dcea449": {
            "title": "Desirable Characteristics for AI Teaching Assistants in Programming Education",
            "abstract": "Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.",
            "pdf_url": "https://export.arxiv.org/pdf/2405.14178v1.pdf",
            "summary": "Students value digital TAs for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines, and expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding.",
        },
    },
}


def search_semantic_scholar(query: str, year: tuple[int, int]) -> dict[str, Paper]:
    if query.lower() not in PAPER_DATA:
        raise ValueError(f"No data for query: {query}")

    return {
        hashed_id: Paper(
            paper_id=hashed_id,
            title=paper["title"],
            abstract=paper["abstract"],
            pdf_url=paper["pdf_url"],
        )
        for paper_id, paper in PAPER_DATA[query.lower()].items()
        if (hashed_id := shake_256(paper_id.encode()).hexdigest(18))
    }
